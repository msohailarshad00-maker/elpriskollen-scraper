name: Scrape All ZIPs (Parallel)

on:
  workflow_dispatch:    # Run manually
  schedule:
    - cron: '0 5 * * 1'  # Every Monday at 5 AM UTC


jobs:
  scrape-zip:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        zip_index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install playwright pandas openpyxl gspread google-auth
          playwright install chromium
          playwright install-deps

      - name: Run scraper for ZIP ${{ matrix.zip_index }}
        env:
          ZIP_INDEX: ${{ matrix.zip_index }}
          HEADLESS: true
        run: |
          python scrape_elpriskollen.py

      - name: Upload to Google Sheets
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_CREDENTIALS }}
        run: |
          echo "$GOOGLE_CREDENTIALS" > credentials.json
          python upload_to_sheets.py

      - name: Cleanup
        if: always()
        run: |
          rm -f credentials.json combined_output.*
